# Wildhacks
WildHacks 2016 Hack!

## Inspiration

We were immediately excited by the possibility that the Tanvas hardware  and the intelligence of Clarifai presented.

## What it does

We wanted to know if it was possible to carry out image-processing flexibly from the device rather than preparing beforehand. On the Tanvas, users are able to select any image and experience the augmented touch sensation.

## How we built it

We used image-segmenting algorithms to pre-process images and conveyed this output to Clarifai

## Challenges we ran into

Before diving into the platform, we expected that Clarifai would provide us with location data rather than just a list of matched objects. To deal with this, we implemented various intermediate processing, as previously described.

## Accomplishments that we're proud of

Many different concepts were brought together in our final product. Developing each individually and then combining everything together was a good challenge.

## What we learned



## What's next for Tanvas-Clarifai

Tanvas and Clarifiai each present many different ways to build from their platform. Building this implementation further could involve further development of the image-segmenting process involving more experimentation to see what sorts of input might allow us to most effectively identify objects and thus apply textures.
